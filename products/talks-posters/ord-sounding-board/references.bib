
@inproceedings{benderDangersStochasticParrots2021,
	address = {Virtual Event Canada},
	title = {On the {Dangers} of {Stochastic} {Parrots}: {Can} {Language} {Models} {Be} {Too} {Big}? ü¶ú},
	isbn = {978-1-4503-8309-7},
	shorttitle = {On the {Dangers} of {Stochastic} {Parrots}},
	url = {https://dl.acm.org/doi/10.1145/3442188.3445922},
	doi = {10.1145/3442188.3445922},
	language = {en},
	urldate = {2025-09-24},
	booktitle = {Proceedings of the 2021 {ACM} {Conference} on {Fairness}, {Accountability}, and {Transparency}},
	publisher = {ACM},
	author = {Bender, Emily M. and Gebru, Timnit and McMillan-Major, Angelina and Shmitchell, Shmargaret},
	month = mar,
	year = {2021},
	pages = {610--623},
}

@inproceedings{longWhatAILiteracy2020,
	address = {Honolulu HI USA},
	title = {What is {AI} {Literacy}? {Competencies} and {Design} {Considerations}},
	isbn = {978-1-4503-6708-0},
	shorttitle = {What is {AI} {Literacy}?},
	url = {https://dl.acm.org/doi/10.1145/3313831.3376727},
	doi = {10.1145/3313831.3376727},
	language = {en},
	urldate = {2025-09-24},
	booktitle = {Proceedings of the 2020 {CHI} {Conference} on {Human} {Factors} in {Computing} {Systems}},
	publisher = {ACM},
	author = {Long, Duri and Magerko, Brian},
	month = apr,
	year = {2020},
	pages = {1--16},
}

@book{loukissasAllDataAre2019b,
	title = {All {Data} {Are} {Local}: {Thinking} {Critically} in a {Data}-{Driven} {Society}},
	copyright = {https://creativecommons.org/licenses/by-nc-nd/4.0/},
	isbn = {978-0-262-35221-5},
	shorttitle = {All {Data} {Are} {Local}},
	url = {https://direct.mit.edu/books/book/4323/All-Data-Are-LocalThinking-Critically-in-a-Data},
	abstract = {How to analyze data settings rather than data sets, acknowledging the meaning-making power of the local.
            In our data-driven society, it is too easy to assume the transparency of data. Instead, Yanni Loukissas argues in All Data Are Local, we should approach data sets with an awareness that data are created by humans and their dutiful machines, at a time, in a place, with the instruments at hand, for audiences that are conditioned to receive them. The term data set implies something discrete, complete, and portable, but it is none of those things. Examining a series of data sources important for understanding the state of public life in the United States‚ÄîHarvard's Arnold Arboretum, the Digital Public Library of America, UCLA's Television News Archive, and the real estate marketplace Zillow‚ÄîLoukissas shows us how to analyze data settings rather than data sets.
            Loukissas sets out six principles: all data are local; data have complex attachments to place; data are collected from heterogeneous sources; data and algorithms are inextricably entangled; interfaces recontextualize data; and data are indexes to local knowledge. He then provides a set of practical guidelines to follow. To make his argument, Loukissas employs a combination of qualitative research on data cultures and exploratory data visualizations. Rebutting the ‚Äúmyth of digital universalism,‚Äù Loukissas reminds us of the meaning-making power of the local.},
	language = {en},
	urldate = {2025-09-24},
	publisher = {The MIT Press},
	author = {Loukissas, Yanni Alexander},
	month = apr,
	year = {2019},
	doi = {10.7551/mitpress/11543.001.0001},
}

@article{muellerItsJustDistributed2025,
	title = {It's just distributed computing: {Rethinking} {AI} governance},
	volume = {49},
	issn = {03085961},
	shorttitle = {It's just distributed computing},
	url = {https://linkinghub.elsevier.com/retrieve/pii/S030859612500014X},
	doi = {10.1016/j.telpol.2025.102917},
	language = {en},
	number = {3},
	urldate = {2025-09-24},
	journal = {Telecommunications Policy},
	author = {Mueller, Milton L.},
	month = apr,
	year = {2025},
	pages = {102917},
}

@misc{offertMethodCriticalAI2024,
	title = {The {Method} of {Critical} {AI} {Studies}, {A} {Propaedeutic}},
	copyright = {arXiv.org perpetual, non-exclusive license},
	url = {https://arxiv.org/abs/2411.18833},
	doi = {10.48550/ARXIV.2411.18833},
	abstract = {We outline some common methodological issues in the field of critical AI studies, including a tendency to overestimate the explanatory power of individual samples (the benchmark casuistry), a dependency on theoretical frameworks derived from earlier conceptualizations of computation (the black box casuistry), and a preoccupation with a cause-and-effect model of algorithmic harm (the stack casuistry). In the face of these issues, we call for, and point towards, a future set of methodologies that might take into account existing strengths in the humanistic close analysis of cultural objects.},
	urldate = {2025-09-24},
	publisher = {arXiv},
	author = {Offert, Fabian and Dhaliwal, Ranjodh Singh},
	year = {2024},
	note = {Version Number: 3},
	keywords = {Computers and Society (cs.CY), FOS: Computer and information sciences},
}

@misc{huberDecodingInequalityKritische2025a,
	title = {Decoding {Inequality}: {Kritische} {Perspektiven} auf {Machine} {Learning} und gesellschaftliche {Ungleichheit}},
	copyright = {Creative Commons Attribution Share Alike 4.0 International},
	shorttitle = {Decoding {Inequality}},
	url = {https://zenodo.org/doi/10.5281/zenodo.16785347},
	abstract = {Die kritische Auseinandersetzung mit Machine-Learning-Systemen und ihren gesellschaftlichen Auswirkungen ist in der heutigen Zeit von h√∂chster Relevanz. W√§hrend KI-Technologien zunehmend Einzug in alle Bereiche unseres Lebens halten - von der Gesundheitsversorgung √ºber die Strafverfolgung bis hin zu Finanzdienstleistungen und sozialen Medien - w√§chst auch ihr Potenzial, bestehende soziale Ungleichheiten zu verst√§rken oder sogar neue zu schaffen. Die F√§higkeit, diese Systeme zu verstehen, ihre Auswirkungen auf bereits minorisierte Gesellschaftsgruppen kritisch zu hinterfragen und L√∂sungen f√ºr eine gerechtere Gestaltung zu entwickeln, ist entscheidend f√ºr eine ethisch verantwortungsvolle und sozial gerechte technologische Zukunft. Dieses Kolloquium bef√§higt Studierende, aktiv an dieser wichtigen gesellschaftlichen Debatte teilzunehmen und tr√§gt zur Entwicklung von KI-Systemen bei, die das Gemeinwohl f√∂rdern und nicht untergraben.

In diesem Kolloquium untersuchen die Studierenden den gesamten Lebenszyklus von Machine-Learning-Systemen und dessen Auswirkungen auf gesellschaftliche Ungleichheit. Der Kurs beleuchtet, wie bewusste und unbewusste menschliche Verzerrungen und Vorurteile in jeder Phase des ML-Lebenszyklus eingebettet werden k√∂nnen und wie diese zu Diskriminierung in verschiedenen gesellschaftlichen Kontexten f√ºhren.

Aufbauend auf den theoretischen Grundlagen der Critical Algorithm Studies lernen die Studierenden, die ethischen, politischen, √∂kologischen und √∂konomischen Implikationen von ML-Technologien zu analysieren. Der Kurs ist entlang des ML-Lebenszyklus strukturiert:

1. Architekturauswahl: Diskussion verschiedener ML-Architekturen und ihrer Auswirkungen auf Modellkapazit√§ten und {\textbackslash}-grenzen. Kritische Betrachtung, wie architektonische Entscheidungen bestimmte Voreingenommenheiten einbetten k√∂nnen.  
2. Datensammlung: Untersuchung von Datenquellen, Kuratierungs- und Filterprozessen. Kritische Perspektiven auf Repr√§sentationsprobleme, Copyright-Fragen und Umweltkosten der Datenspeicherung.  
3. Training: Technische Aspekte des Trainingsprozesses und Auswahl von Hyperparametern. Kritische Betrachtung der Umweltauswirkungen, Arbeitsbedingungen in der KI-Industrie und Machtkonzentration bei ressourcenstarken Unternehmen.  
4. Anwendung: Analyse verschiedener Anwendungsf√§lle von ML-Systemen, Feinabstimmung f√ºr spezifische Aufgaben und Bereitstellungsstrategien. Kritische Diskussion ethischer √úberlegungen, potenzieller Missbrauchsszenarien und Fragen der Transparenz und Erkl√§rbarkeit.  
5. Evaluation und √úberwachung: Methoden zur Bewertung von Modellleistung und Verzerrungen. Kritische Perspektiven auf die Grenzen aktueller Evaluierungsmetriken.  
6. Governance und Regulierung: Diskussion aktueller und vorgeschlagener Regulierungsrahmen, ethischer Richtlinien und Herausforderungen bei der Steuerung sich schnell entwickelnder KI-Technologien.

Durchgehend wird betont, dass die Entwicklung und der Einsatz von ML-Systemen auch als Gesch√§ftsmodell zu verstehen sind. Die Studierenden lernen, die kommerziellen Interessen und wirtschaftlichen Auswirkungen zu analysieren, die die Gestaltung und den Einsatz dieser Technologien beeinflussen.

Der Kurs kombiniert theoretische Reflexion mit praktischen √úbungen. Die Studierenden werden sowohl mit den theoretischen (nicht-mathematischen) Grundlagen des maschinellen Lernens vertraut gemacht als auch in die Lage versetzt, kritische Analysen auf Basis aktueller Forschungsergebnisse durchzuf√ºhren und die implikationen f√ºr minorisierte Bev√∂lkerungsgruppen von KI in der Gesellschaft zu verstehen. Praktische Beispiele, Fallstudien und Diskussionen aktueller Forschungsarbeiten werden regelm√§ssig in die Lehrveranstaltung integriert, um die Verbindung zwischen technologischen Entwicklungen und ihren gesellschaftlichen Auswirkungen zu verdeutlichen.},
	urldate = {2025-09-24},
	publisher = {Zenodo},
	author = {Huber, Rachel and M√§hr, Moritz},
	month = aug,
	year = {2025},
	doi = {10.5281/ZENODO.16785347},
	keywords = {Critical Algorithm Studies, Digital Humanities, Machine Learning},
}
